# Отчёт по заданию 1 «Модификация существующих моделей»

## 1.2

Вывод:

<--- Конфигурация ---
Источник данных: breast_cancer
Количество образцов: 500
Количество признаков: 30
Количество классов: 2
Размер батча: 32
Эпохи: 200
Скорость обучения: 0.1
Путь сохранения модели: models/logreg_torch_refactored.pth
Имена классов: ['malignant', 'benign']
------------------------------

Размер датасета: 569
Количество батчей: 18

Архитектура модели:
LogisticRegression(
  (linear): Linear(in_features=30, out_features=2, bias=True)
)

--- Начало обучения модели ---
Epoch 010: loss=4065.6453, accuracy=0.7786, precision=0.8598, recall=0.7731, f1_score=0.8142, roc_auc=0.7812
Epoch 020: loss=1572.7329, accuracy=0.8858, precision=0.9171, recall=0.8992, f1_score=0.9081, roc_auc=0.8824
Epoch 030: loss=1193.5975, accuracy=0.8928, precision=0.9205, recall=0.9076, f1_score=0.9140, roc_auc=0.8877
Epoch 040: loss=1860.6134, accuracy=0.8647, precision=0.9000, recall=0.8824, f1_score=0.8911, roc_auc=0.8595
Epoch 050: loss=1304.7825, accuracy=0.8981, precision=0.9235, recall=0.9132, f1_score=0.9183, roc_auc=0.8941
Epoch 060: loss=1156.1173, accuracy=0.9051, precision=0.9244, recall=0.9244, f1_score=0.9244, roc_auc=0.8985
Epoch 070: loss=1217.5299, accuracy=0.8910, precision=0.9155, recall=0.9104, f1_score=0.9129, roc_auc=0.8840
Epoch 080: loss=2472.6260, accuracy=0.8313, precision=0.8783, recall=0.8487, f1_score=0.8632, roc_auc=0.8253
Epoch 090: loss=2249.1160, accuracy=0.8664, precision=0.8958, recall=0.8908, f1_score=0.8933, roc_auc=0.8581
Epoch 100: loss=972.8635, accuracy=0.9104, precision=0.9298, recall=0.9272, f1_score=0.9285, roc_auc=0.9046
Epoch 110: loss=2025.1316, accuracy=0.8752, precision=0.9086, recall=0.8908, f1_score=0.8996, roc_auc=0.8699
Epoch 120: loss=2560.9409, accuracy=0.8330, precision=0.8786, recall=0.8515, f1_score=0.8649, roc_auc=0.8287
Epoch 130: loss=1587.5842, accuracy=0.8717, precision=0.9128, recall=0.8796, f1_score=0.8959, roc_auc=0.8690
Epoch 140: loss=1829.2620, accuracy=0.8594, precision=0.8901, recall=0.8852, f1_score=0.8876, roc_auc=0.8506
Epoch 150: loss=1137.0895, accuracy=0.8963, precision=0.9116, recall=0.9244, f1_score=0.9179, roc_auc=0.8879
Epoch 160: loss=1056.8305, accuracy=0.9139, precision=0.9350, recall=0.9272, f1_score=0.9311, roc_auc=0.9093
Epoch 170: loss=1273.7553, accuracy=0.8981, precision=0.9188, recall=0.9188, f1_score=0.9188, roc_auc=0.8910
Epoch 180: loss=1059.0733, accuracy=0.9033, precision=0.9194, recall=0.9272, f1_score=0.9233, roc_auc=0.8952
Epoch 190: loss=1474.5684, accuracy=0.8805, precision=0.9164, recall=0.8908, f1_score=0.9034, roc_auc=0.8794
Epoch 200: loss=1096.7878, accuracy=0.9016, precision=0.9216, recall=0.9216, f1_score=0.9216, roc_auc=0.8946
--- Обучение завершено ---

Модель сохранена в models/logreg_torch_refactored.pth
Модель загружена из models/logreg_torch_refactored.pth

--- Начало оценки модели ---

--- Результаты оценки ---
Accuracy: 0.9033
Precision: 0.9415
Recall: 0.9020
F1 score: 0.9213
Roc auc: 0.9038
--- Оценка завершена --- >

---

# Отчёт по заданию 2 «Работа с датасетами»

## 2.1

### Вывод

Используется устройство: cpu
==================================================
НАЧИНАЕМ ЗАДАЧУ РЕГРЕССИИ (Auto MPG)
==================================================
Загрузка Auto MPG данных из локального файла: data/auto-mpg.data
Размерность входных признаков для регрессии: 9

--- Начало обучения для REGRESSION ---
Эпоха 1/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 177.76it/s, loss=638]
Эпоха 1/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1503.16it/s, val_loss=714]
Эпоха 1/100, Обучение Loss: 638.0112, Валидация Loss: 714.2695, RMSE: 26.2978
  > Сохранена лучшая модель с валидационным лоссом: 714.2695
Эпоха 2/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 888.11it/s, loss=603]
Эпоха 2/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1496.90it/s, val_loss=700]
Эпоха 3/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 999.63it/s, loss=586]
Эпоха 3/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1502.62it/s, val_loss=686]
Эпоха 4/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 999.33it/s, loss=582]
Эпоха 2/100, Обучение Loss: 603.4130, Валидация Loss: 699.5672, RMSE: 26.0340
  > Сохранена лучшая модель с валидационным лоссом: 699.5672
Эпоха 3/100, Обучение Loss: 586.1873, Валидация Loss: 685.8613, RMSE: 25.7851
  > Сохранена лучшая модель с валидационным лоссом: 685.8613
Эпоха 4/100, Обучение Loss: 581.8721, Валидация Loss: 672.8456, RMSE: 25.5457
  > Сохранена лучшая модель с валидационным лоссом: 672.8456
Эпоха 4/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1504.59it/s, val_loss=673]
Эпоха 5/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 888.36it/s, loss=565]
Эпоха 5/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1506.39it/s, val_loss=660]
Эпоха 6/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 727.94it/s, loss=563]
Эпоха 5/100, Обучение Loss: 565.2927, Валидация Loss: 660.1691, RMSE: 25.3102
  > Сохранена лучшая модель с валидационным лоссом: 660.1691
Эпоха 6/100, Обучение Loss: 563.3833, Валидация Loss: 647.4513, RMSE: 25.0725
  > Сохранена лучшая модель с валидационным лоссом: 647.4513
Эпоха 7/100, Обучение Loss: 561.5626, Валидация Loss: 634.8177, RMSE: 24.8344
  > Сохранена лучшая модель с валидационным лоссом: 634.8177
Эпоха 6/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1499.04it/s, val_loss=647]
Эпоха 7/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 1000.58it/s, loss=562]
Эпоха 7/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1495.30it/s, val_loss=635]
Эпоха 8/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 726.76it/s, loss=551]
Эпоха 8/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1499.75it/s, val_loss=622]
Эпоха 9/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 1142.78it/s, loss=536]
Эпоха 9/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 2995.93it/s, val_loss=610]
Эпоха 10/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 996.30it/s, loss=525]
Эпоха 8/100, Обучение Loss: 551.1684, Валидация Loss: 622.3761, RMSE: 24.5983
  > Сохранена лучшая модель с валидационным лоссом: 622.3761

...

Эпоха 97/100, Обучение Loss: 127.7585, Валидация Loss: 149.7192, RMSE: 12.0813
  > Сохранена лучшая модель с валидационным лоссом: 149.7192
Эпоха 96/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 3001.65it/s, val_loss=152]
Эпоха 97/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 999.80it/s, loss=128]
Эпоха 97/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 3003.08it/s, val_loss=150]
Эпоха 98/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 889.35it/s, loss=128]
Эпоха 98/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 3001.65it/s, val_loss=147]
Эпоха 99/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 999.39it/s, loss=122]
Эпоха 99/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1503.51it/s, val_loss=145]
Эпоха 100/100 (Обучение): 100%|██████████| 8/8 [00:00<00:00, 727.28it/s, loss=123]
Эпоха 98/100, Обучение Loss: 127.5098, Валидация Loss: 147.3874, RMSE: 11.9849
  > Сохранена лучшая модель с валидационным лоссом: 147.3874
Эпоха 99/100, Обучение Loss: 122.4642, Валидация Loss: 144.9323, RMSE: 11.8842
  > Сохранена лучшая модель с валидационным лоссом: 144.9323
Эпоха 100/100, Обучение Loss: 122.5636, Валидация Loss: 142.4741, RMSE: 11.7825
  > Сохранена лучшая модель с валидационным лоссом: 142.4741
--- Обучение для REGRESSION завершено ---

Оценка модели регрессии на тестовой выборке:
RMSE на тестовой выборке: 11.1976


==================================================
НАЧИНАЕМ ЗАДАЧУ БИНАРНОЙ КЛАССИФИКАЦИИ (Pima Indians Diabetes)
==================================================
Загрузка Pima Indians Diabetes данных из локального файла: data/diabetes.csv
Эпоха 100/100 (Валидация): 100%|██████████| 3/3 [00:00<00:00, 1500.82it/s, val_loss=142]
Размерность входных признаков для классификации: 8

--- Начало обучения для CLASSIFICATION ---
Эпоха 1/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 651.93it/s, loss=0.633]
Эпоха 1/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 1000.12it/s, val_loss=0.599]
Эпоха 2/100 (Обучение):   0%|          | 0/15 [00:00<?, ?it/s, loss=0.599]Эпоха 1/100, Обучение Loss: 0.6330, Валидация Loss: 0.5993, Accuracy: 0.7013, F1-Score: 0.5490
  > Сохранена лучшая модель с валидационным лоссом: 0.5993
Эпоха 2/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 600.16it/s, loss=0.578]
Эпоха 2/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 1668.25it/s, val_loss=0.552]
Эпоха 3/100 (Обучение):   0%|          | 0/15 [00:00<?, ?it/s, loss=0.535]Эпоха 2/100, Обучение Loss: 0.5779, Валидация Loss: 0.5521, Accuracy: 0.7208, F1-Score: 0.5657
  > Сохранена лучшая модель с валидационным лоссом: 0.5521
Эпоха 3/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 833.33it/s, loss=0.543]
Эпоха 3/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 1665.73it/s, val_loss=0.522]
Эпоха 4/100 (Обучение):   0%|          | 0/15 [00:00<?, ?it/s, loss=0.558]Эпоха 3/100, Обучение Loss: 0.5428, Валидация Loss: 0.5223, Accuracy: 0.7532, F1-Score: 0.6122
  > Сохранена лучшая модель с валидационным лоссом: 0.5223
Эпоха 4/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 652.25it/s, loss=0.52]
Эпоха 4/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 2488.61it/s, val_loss=0.503]
Эпоха 5/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 937.48it/s, loss=0.509]
Эпоха 4/100, Обучение Loss: 0.5201, Валидация Loss: 0.5032, Accuracy: 0.7532, F1-Score: 0.6122
  > Сохранена лучшая модель с валидационным лоссом: 0.5032

...

Эпоха 95/100, Обучение Loss: 0.4669, Валидация Loss: 0.4555, Accuracy: 0.7727, F1-Score: 0.5882
Эпоха 96/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 2499.59it/s, val_loss=0.454]
Эпоха 97/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 999.64it/s, loss=0.473]
Эпоха 96/100, Обучение Loss: 0.4829, Валидация Loss: 0.4542, Accuracy: 0.7727, F1-Score: 0.5882
Эпоха 97/100, Обучение Loss: 0.4727, Валидация Loss: 0.4561, Accuracy: 0.7792, F1-Score: 0.5952
Эпоха 97/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 1677.72it/s, val_loss=0.456]
Эпоха 98/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 832.97it/s, loss=0.496]
Эпоха 98/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 1671.04it/s, val_loss=0.453]
Эпоха 99/100 (Обучение):   0%|          | 0/15 [00:00<?, ?it/s, loss=0.482]Эпоха 98/100, Обучение Loss: 0.4965, Валидация Loss: 0.4532, Accuracy: 0.7662, F1-Score: 0.5814
Эпоха 99/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 881.92it/s, loss=0.481]
Эпоха 99/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 1669.04it/s, val_loss=0.453]
Эпоха 100/100 (Обучение):   0%|          | 0/15 [00:00<?, ?it/s, loss=0.477]Эпоха 99/100, Обучение Loss: 0.4811, Валидация Loss: 0.4526, Accuracy: 0.7792, F1-Score: 0.6047
Эпоха 100/100 (Обучение): 100%|██████████| 15/15 [00:00<00:00, 833.27it/s, loss=0.48]
Эпоха 100/100 (Валидация): 100%|██████████| 5/5 [00:00<00:00, 1667.58it/s, val_loss=0.451]
Эпоха 100/100, Обучение Loss: 0.4805, Валидация Loss: 0.4509, Accuracy: 0.7792, F1-Score: 0.5952
--- Обучение для CLASSIFICATION завершено ---

Оценка модели классификации на тестовой выборке:
Accuracy на тестовой выборке: 0.7273
F1-Score на тестовой выборке: 0.6316
---

## Выводы

1. Для задачи регрессии (Auto MPG): Расширенные признаки (полиномиальные + статистические) улучшили качество модели


2. Для задачи классификации (Diabetes): Прирост качества менее значительный, чем в регрессии. Увеличение вычислительных затрат.

3. Общие рекомендации:
- Для данного типа данных:
  - Полиномиальные признаки 2-й степени показали хороший баланс между качеством и сложностью
  - Статистические признаки по строкам оказались полезными дополнениями
- Дальнейшие улучшения могут включать:
  - Отбор наиболее значимых признаков (например, с помощью L1-регуляризации)
  - Эксперименты с другими преобразованиями (логарифмирование, бининг)
  - Увеличение степени полиномов для регрессионной задачи
- В production-решении:
  - Для регрессии целесообразно использовать расширенную модель
  - Для классификации можно рассмотреть более простую модель, если прирост Accuracy не критичен

Итог: Создание дополнительных признаков является эффективным методом улучшения качества моделей, особенно для регрессионных задач. Однако всегда необходимо учитывать баланс между улучшением метрик и увеличением сложности модели.