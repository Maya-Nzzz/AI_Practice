# Отчёт по заданию 1 "Стандартные аугментации torchvision"

1. Загружаю 5 случайных изображений из 5 разных классов.
2. Создала отдельные трансформации:
    * горизонтальный флип
    * кроп
    * изменение цвета
    * поворот
    * перевод в оттенки серого
3. Создала комбинированную цепочку из всех аугментаций.
4. В результате: оригинал + результат каждой аугментации отдельно + общий результат.

# Отчёт по заданию 2 "Кастомные аугментации"

Реализовала 3 кастомные аугментации:

1. **Случайное гауссово размытие** — случайно размывает изображение, имитируя дефокусировку.
2. **Случайная перспектива** — случайно искажает перспективу, добавляя "эффект наклона".
3. **Случайная яркость и контрастность** — случайно изменяет яркость и контраст, чтобы изображение выглядело светлее или
   темнее.

Применила готовые аугментациями из extra_augs.py. Их можно увидеть в папку результатов.

# Отчёт по заданию 3 "Анализ датасета"

**Результаты работы:**

* Минимальная ширина: 210 пикселей
* Максимальная ширина: 736 пикселей
* Средняя ширина: 538.89 пикселей
* Минимальная высота: 240 пикселей
* Максимальная высота: 1308 пикселей
* Средняя высота: 623.56 пикселей

# Отчёт по заданию 4 "Pipeline аугментаций"

**Класс AugmentationPipeline:**

* Позволяет добавлять, удалять и применять аугментации по имени.
* Гибко управляется через словарь augmentations.

**Конфигурации:**

* light: минимальные аугментации (resize + лёгкий флип).
* medium: больше случайных изменений (флип, поворот).
* heavy: агрессивные (флип, сильный поворот, изменение цвета).

# Отчёт по заданию 5 "Эксперимент с размерами"

**Результаты эксперимента с размерами изображений:**

* Минимальное время обработки: 0.15 сек (512x512)
* Максимальное время обработки: 0.68 сек (224x224)
* Среднее время обработки: 0.29 сек
* Минимальное потребление памяти: -3.23 MB (512x512)
* Максимальное потребление памяти: 59.97 MB (64x64)
* Среднее потребление памяти: 14.57 MB

# Отчёт по заданию 6 "Дообучение предобученных моделей"

**Результаты обучения модели EfficientNetB0:**

| Эпоха | Train Loss | Train Acc | Val Loss | Val Acc |
|-------|------------|-----------|----------|---------|
| 1     | 1.5759     | 39.4%     | 0.9258   | 81.2%   |
| 2     | 0.5013     | 92.8%     | 0.3801   | 87.2%   |
| 3     | 0.1009     | 99.4%     | 0.3913   | 87.7%   |
